{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb795b70-d21b-4f38-94f1-6cc7d00d3875",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier   # use MLPRegressor if regression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8d67b11-5061-449b-942d-9bd8527e25b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features_data = pd.read_csv(\"/Users/suhaniagarwal/Downloads/all_features_data.csv\")\n",
    "all_features_change = all_features_data.drop([\"temperature_2m_mean (°C)\", \"temperature_2m_min (°C)\", \"apparent_temperature_mean (°C)\",\"apparent_temperature_min (°C)\",\"apparent_temperature_max (°C)\",\"wind_direction_10m_dominant (°)\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9912c5f5-d80f-4068-8aae-7f6c9384497c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>PM2.5 (µg/m³)</th>\n",
       "      <th>PM10 (µg/m³)</th>\n",
       "      <th>NO (µg/m³)</th>\n",
       "      <th>NO2 (µg/m³)</th>\n",
       "      <th>NOx (ppb)</th>\n",
       "      <th>NH3 (µg/m³)</th>\n",
       "      <th>SO2 (µg/m³)</th>\n",
       "      <th>CO (mg/m³)</th>\n",
       "      <th>Ozone (µg/m³)</th>\n",
       "      <th>...</th>\n",
       "      <th>temperature_2m_mean (°C)</th>\n",
       "      <th>temperature_2m_max (°C)</th>\n",
       "      <th>temperature_2m_min (°C)</th>\n",
       "      <th>apparent_temperature_mean (°C)</th>\n",
       "      <th>apparent_temperature_max (°C)</th>\n",
       "      <th>apparent_temperature_min (°C)</th>\n",
       "      <th>wind_speed_10m_max (km/h)</th>\n",
       "      <th>wind_gusts_10m_max (km/h)</th>\n",
       "      <th>wind_direction_10m_dominant (°)</th>\n",
       "      <th>Number of Admissions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-05-01</td>\n",
       "      <td>38.350</td>\n",
       "      <td>61.36</td>\n",
       "      <td>16.18</td>\n",
       "      <td>5.71</td>\n",
       "      <td>116.68</td>\n",
       "      <td>50.755</td>\n",
       "      <td>1.82</td>\n",
       "      <td>0.700</td>\n",
       "      <td>25.85</td>\n",
       "      <td>...</td>\n",
       "      <td>26.9</td>\n",
       "      <td>35.6</td>\n",
       "      <td>17.4</td>\n",
       "      <td>26.3</td>\n",
       "      <td>36.0</td>\n",
       "      <td>16.9</td>\n",
       "      <td>13.7</td>\n",
       "      <td>29.5</td>\n",
       "      <td>8</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-05-02</td>\n",
       "      <td>48.600</td>\n",
       "      <td>77.75</td>\n",
       "      <td>15.48</td>\n",
       "      <td>5.74</td>\n",
       "      <td>116.68</td>\n",
       "      <td>50.755</td>\n",
       "      <td>4.74</td>\n",
       "      <td>0.900</td>\n",
       "      <td>43.53</td>\n",
       "      <td>...</td>\n",
       "      <td>29.4</td>\n",
       "      <td>37.8</td>\n",
       "      <td>19.4</td>\n",
       "      <td>27.7</td>\n",
       "      <td>38.1</td>\n",
       "      <td>16.9</td>\n",
       "      <td>17.2</td>\n",
       "      <td>29.5</td>\n",
       "      <td>46</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-05-03</td>\n",
       "      <td>46.940</td>\n",
       "      <td>75.10</td>\n",
       "      <td>18.65</td>\n",
       "      <td>4.80</td>\n",
       "      <td>116.68</td>\n",
       "      <td>50.755</td>\n",
       "      <td>2.38</td>\n",
       "      <td>1.190</td>\n",
       "      <td>19.42</td>\n",
       "      <td>...</td>\n",
       "      <td>30.2</td>\n",
       "      <td>36.8</td>\n",
       "      <td>25.1</td>\n",
       "      <td>28.4</td>\n",
       "      <td>35.9</td>\n",
       "      <td>23.7</td>\n",
       "      <td>19.1</td>\n",
       "      <td>40.7</td>\n",
       "      <td>39</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-05-04</td>\n",
       "      <td>57.095</td>\n",
       "      <td>119.76</td>\n",
       "      <td>15.73</td>\n",
       "      <td>14.73</td>\n",
       "      <td>116.68</td>\n",
       "      <td>50.755</td>\n",
       "      <td>1.82</td>\n",
       "      <td>0.645</td>\n",
       "      <td>11.61</td>\n",
       "      <td>...</td>\n",
       "      <td>29.2</td>\n",
       "      <td>36.0</td>\n",
       "      <td>23.6</td>\n",
       "      <td>28.1</td>\n",
       "      <td>37.4</td>\n",
       "      <td>21.9</td>\n",
       "      <td>18.8</td>\n",
       "      <td>35.3</td>\n",
       "      <td>20</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-05-05</td>\n",
       "      <td>75.770</td>\n",
       "      <td>121.22</td>\n",
       "      <td>8.48</td>\n",
       "      <td>8.62</td>\n",
       "      <td>116.68</td>\n",
       "      <td>50.755</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.490</td>\n",
       "      <td>32.05</td>\n",
       "      <td>...</td>\n",
       "      <td>29.5</td>\n",
       "      <td>38.0</td>\n",
       "      <td>20.9</td>\n",
       "      <td>28.6</td>\n",
       "      <td>37.7</td>\n",
       "      <td>19.5</td>\n",
       "      <td>15.3</td>\n",
       "      <td>33.8</td>\n",
       "      <td>326</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>2019-03-27</td>\n",
       "      <td>56.110</td>\n",
       "      <td>94.46</td>\n",
       "      <td>14.94</td>\n",
       "      <td>1.30</td>\n",
       "      <td>12.39</td>\n",
       "      <td>21.310</td>\n",
       "      <td>10.59</td>\n",
       "      <td>0.000</td>\n",
       "      <td>23.20</td>\n",
       "      <td>...</td>\n",
       "      <td>21.9</td>\n",
       "      <td>29.6</td>\n",
       "      <td>13.9</td>\n",
       "      <td>23.0</td>\n",
       "      <td>30.9</td>\n",
       "      <td>13.3</td>\n",
       "      <td>11.2</td>\n",
       "      <td>24.5</td>\n",
       "      <td>324</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>2019-03-28</td>\n",
       "      <td>28.690</td>\n",
       "      <td>73.86</td>\n",
       "      <td>27.43</td>\n",
       "      <td>9.46</td>\n",
       "      <td>32.22</td>\n",
       "      <td>43.840</td>\n",
       "      <td>9.62</td>\n",
       "      <td>0.000</td>\n",
       "      <td>40.74</td>\n",
       "      <td>...</td>\n",
       "      <td>23.8</td>\n",
       "      <td>30.6</td>\n",
       "      <td>18.0</td>\n",
       "      <td>25.4</td>\n",
       "      <td>32.1</td>\n",
       "      <td>18.9</td>\n",
       "      <td>11.1</td>\n",
       "      <td>25.6</td>\n",
       "      <td>332</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>2019-03-29</td>\n",
       "      <td>47.540</td>\n",
       "      <td>81.34</td>\n",
       "      <td>40.21</td>\n",
       "      <td>10.34</td>\n",
       "      <td>47.18</td>\n",
       "      <td>50.500</td>\n",
       "      <td>19.67</td>\n",
       "      <td>0.000</td>\n",
       "      <td>34.93</td>\n",
       "      <td>...</td>\n",
       "      <td>24.3</td>\n",
       "      <td>31.8</td>\n",
       "      <td>17.5</td>\n",
       "      <td>25.6</td>\n",
       "      <td>33.5</td>\n",
       "      <td>18.5</td>\n",
       "      <td>11.0</td>\n",
       "      <td>24.1</td>\n",
       "      <td>316</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>2019-03-30</td>\n",
       "      <td>52.130</td>\n",
       "      <td>88.82</td>\n",
       "      <td>65.08</td>\n",
       "      <td>10.78</td>\n",
       "      <td>66.81</td>\n",
       "      <td>66.040</td>\n",
       "      <td>37.93</td>\n",
       "      <td>0.000</td>\n",
       "      <td>36.24</td>\n",
       "      <td>...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>32.2</td>\n",
       "      <td>18.3</td>\n",
       "      <td>24.6</td>\n",
       "      <td>34.9</td>\n",
       "      <td>17.1</td>\n",
       "      <td>21.7</td>\n",
       "      <td>44.6</td>\n",
       "      <td>334</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>2019-03-31</td>\n",
       "      <td>36.570</td>\n",
       "      <td>69.92</td>\n",
       "      <td>42.93</td>\n",
       "      <td>8.72</td>\n",
       "      <td>46.20</td>\n",
       "      <td>59.200</td>\n",
       "      <td>35.21</td>\n",
       "      <td>0.000</td>\n",
       "      <td>40.09</td>\n",
       "      <td>...</td>\n",
       "      <td>22.5</td>\n",
       "      <td>30.3</td>\n",
       "      <td>16.7</td>\n",
       "      <td>21.5</td>\n",
       "      <td>28.9</td>\n",
       "      <td>16.2</td>\n",
       "      <td>18.7</td>\n",
       "      <td>38.2</td>\n",
       "      <td>311</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>700 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Timestamp  PM2.5 (µg/m³)  PM10 (µg/m³)  NO (µg/m³)  NO2 (µg/m³)  \\\n",
       "0    2017-05-01         38.350         61.36       16.18         5.71   \n",
       "1    2017-05-02         48.600         77.75       15.48         5.74   \n",
       "2    2017-05-03         46.940         75.10       18.65         4.80   \n",
       "3    2017-05-04         57.095        119.76       15.73        14.73   \n",
       "4    2017-05-05         75.770        121.22        8.48         8.62   \n",
       "..          ...            ...           ...         ...          ...   \n",
       "695  2019-03-27         56.110         94.46       14.94         1.30   \n",
       "696  2019-03-28         28.690         73.86       27.43         9.46   \n",
       "697  2019-03-29         47.540         81.34       40.21        10.34   \n",
       "698  2019-03-30         52.130         88.82       65.08        10.78   \n",
       "699  2019-03-31         36.570         69.92       42.93         8.72   \n",
       "\n",
       "     NOx (ppb)  NH3 (µg/m³)  SO2 (µg/m³)  CO (mg/m³)  Ozone (µg/m³)  ...  \\\n",
       "0       116.68       50.755         1.82       0.700          25.85  ...   \n",
       "1       116.68       50.755         4.74       0.900          43.53  ...   \n",
       "2       116.68       50.755         2.38       1.190          19.42  ...   \n",
       "3       116.68       50.755         1.82       0.645          11.61  ...   \n",
       "4       116.68       50.755         0.99       0.490          32.05  ...   \n",
       "..         ...          ...          ...         ...            ...  ...   \n",
       "695      12.39       21.310        10.59       0.000          23.20  ...   \n",
       "696      32.22       43.840         9.62       0.000          40.74  ...   \n",
       "697      47.18       50.500        19.67       0.000          34.93  ...   \n",
       "698      66.81       66.040        37.93       0.000          36.24  ...   \n",
       "699      46.20       59.200        35.21       0.000          40.09  ...   \n",
       "\n",
       "     temperature_2m_mean (°C)  temperature_2m_max (°C)  \\\n",
       "0                        26.9                     35.6   \n",
       "1                        29.4                     37.8   \n",
       "2                        30.2                     36.8   \n",
       "3                        29.2                     36.0   \n",
       "4                        29.5                     38.0   \n",
       "..                        ...                      ...   \n",
       "695                      21.9                     29.6   \n",
       "696                      23.8                     30.6   \n",
       "697                      24.3                     31.8   \n",
       "698                      24.0                     32.2   \n",
       "699                      22.5                     30.3   \n",
       "\n",
       "     temperature_2m_min (°C)  apparent_temperature_mean (°C)  \\\n",
       "0                       17.4                            26.3   \n",
       "1                       19.4                            27.7   \n",
       "2                       25.1                            28.4   \n",
       "3                       23.6                            28.1   \n",
       "4                       20.9                            28.6   \n",
       "..                       ...                             ...   \n",
       "695                     13.9                            23.0   \n",
       "696                     18.0                            25.4   \n",
       "697                     17.5                            25.6   \n",
       "698                     18.3                            24.6   \n",
       "699                     16.7                            21.5   \n",
       "\n",
       "     apparent_temperature_max (°C)  apparent_temperature_min (°C)  \\\n",
       "0                             36.0                           16.9   \n",
       "1                             38.1                           16.9   \n",
       "2                             35.9                           23.7   \n",
       "3                             37.4                           21.9   \n",
       "4                             37.7                           19.5   \n",
       "..                             ...                            ...   \n",
       "695                           30.9                           13.3   \n",
       "696                           32.1                           18.9   \n",
       "697                           33.5                           18.5   \n",
       "698                           34.9                           17.1   \n",
       "699                           28.9                           16.2   \n",
       "\n",
       "     wind_speed_10m_max (km/h)  wind_gusts_10m_max (km/h)  \\\n",
       "0                         13.7                       29.5   \n",
       "1                         17.2                       29.5   \n",
       "2                         19.1                       40.7   \n",
       "3                         18.8                       35.3   \n",
       "4                         15.3                       33.8   \n",
       "..                         ...                        ...   \n",
       "695                       11.2                       24.5   \n",
       "696                       11.1                       25.6   \n",
       "697                       11.0                       24.1   \n",
       "698                       21.7                       44.6   \n",
       "699                       18.7                       38.2   \n",
       "\n",
       "     wind_direction_10m_dominant (°)  Number of Admissions  \n",
       "0                                  8                  28.0  \n",
       "1                                 46                  14.0  \n",
       "2                                 39                  15.0  \n",
       "3                                 20                  17.0  \n",
       "4                                326                  23.0  \n",
       "..                               ...                   ...  \n",
       "695                              324                  23.0  \n",
       "696                              332                  41.0  \n",
       "697                              316                  27.0  \n",
       "698                              334                  13.0  \n",
       "699                              311                   6.0  \n",
       "\n",
       "[700 rows x 23 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "820d3d46-111b-48cb-9b9a-7798b0e86a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FNN (Random Split)\n",
      "R²   : 0.07327985254929115\n",
      "RMSE: 7.544537746448478\n",
      "MAE : 6.0100825255851875\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "\n",
    "y_fnn_rand = all_features_data[\"Number of Admissions\"]\n",
    "\n",
    "X_fnn_rand = all_features_data.drop(\n",
    "    columns=[\"Number of Admissions\", \"Timestamp\"]\n",
    ")\n",
    "\n",
    "\n",
    "X_train_fnn_rand, X_test_fnn_rand, y_train_fnn_rand, y_test_fnn_rand = train_test_split(\n",
    "    X_fnn_rand,\n",
    "    y_fnn_rand,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "\n",
    "fnn_rand = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"fnn\", MLPRegressor(\n",
    "        hidden_layer_sizes=(64, 32),\n",
    "        activation=\"relu\",\n",
    "        solver=\"adam\",\n",
    "        alpha=1e-4,\n",
    "        learning_rate_init=0.001,\n",
    "        max_iter=1000,\n",
    "        early_stopping=True,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "\n",
    "fnn_rand.fit(X_train_fnn_rand, y_train_fnn_rand)\n",
    "y_pred_fnn_rand = fnn_rand.predict(X_test_fnn_rand)\n",
    "\n",
    "print(\"FNN (Random Split)\")\n",
    "print(\"R²   :\", r2_score(y_test_fnn_rand, y_pred_fnn_rand))\n",
    "print(\"RMSE:\", np.sqrt(mean_squared_error(y_test_fnn_rand, y_pred_fnn_rand)))\n",
    "print(\"MAE :\", mean_absolute_error(y_test_fnn_rand, y_pred_fnn_rand))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ce05a70-5fe5-4674-99de-55d0aab3e7fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FNN (Time-Aware Split)\n",
      "R²   : -0.7639239269403026\n",
      "RMSE: 9.846663851840074\n",
      "MAE : 7.930891925680254\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "\n",
    "y_fnn_time = all_features_data[\"Number of Admissions\"]\n",
    "\n",
    "X_fnn_time = all_features_data.drop(\n",
    "    columns=[\"Number of Admissions\", \"Timestamp\"]\n",
    ")\n",
    "\n",
    "\n",
    "split_date = \"2018-11-01\"\n",
    "\n",
    "train_idx = all_features_data[\"Timestamp\"] < split_date\n",
    "test_idx  = all_features_data[\"Timestamp\"] >= split_date\n",
    "\n",
    "X_train_fnn_time = X_fnn_time.loc[train_idx]\n",
    "X_test_fnn_time  = X_fnn_time.loc[test_idx]\n",
    "\n",
    "y_train_fnn_time = y_fnn_time.loc[train_idx]\n",
    "y_test_fnn_time  = y_fnn_time.loc[test_idx]\n",
    "\n",
    "fnn_time = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"fnn\", MLPRegressor(\n",
    "        hidden_layer_sizes=(64, 32),\n",
    "        activation=\"relu\",\n",
    "        solver=\"adam\",\n",
    "        alpha=1e-4,\n",
    "        learning_rate_init=0.001,\n",
    "        max_iter=1000,\n",
    "        early_stopping=True,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "\n",
    "fnn_time.fit(X_train_fnn_time, y_train_fnn_time)\n",
    "y_pred_fnn_time = fnn_time.predict(X_test_fnn_time)\n",
    "\n",
    "print(\"FNN (Time-Aware Split)\")\n",
    "print(\"R²   :\", r2_score(y_test_fnn_time, y_pred_fnn_time))\n",
    "print(\"RMSE:\", np.sqrt(mean_squared_error(y_test_fnn_time, y_pred_fnn_time)))\n",
    "print(\"MAE :\", mean_absolute_error(y_test_fnn_time, y_pred_fnn_time))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ee3a2fb-a124-4fff-9b8e-9de4b52b8b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR (Random Split)\n",
      "R²   : 0.13668994281443803\n",
      "RMSE: 7.2818500804764925\n",
      "MAE : 5.801893767372201\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "\n",
    "y_svr = all_features_data[\"Number of Admissions\"]\n",
    "\n",
    "X_svr = all_features_data.drop(\n",
    "    columns=[\"Number of Admissions\", \"Timestamp\"]\n",
    ")\n",
    "\n",
    "X_train_svr, X_test_svr, y_train_svr, y_test_svr = train_test_split(\n",
    "    X_svr, y_svr, test_size=0.2, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "\n",
    "svr_pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"svr\", SVR(kernel=\"rbf\", C=10, epsilon=0.1))\n",
    "])\n",
    "\n",
    "svr_pipeline.fit(X_train_svr, y_train_svr)\n",
    "\n",
    "y_pred_svr = svr_pipeline.predict(X_test_svr)\n",
    "\n",
    "print(\"SVR (Random Split)\")\n",
    "print(\"R²   :\", r2_score(y_test_svr, y_pred_svr))\n",
    "print(\"RMSE:\", np.sqrt(mean_squared_error(y_test_svr, y_pred_svr)))\n",
    "print(\"MAE :\", mean_absolute_error(y_test_svr, y_pred_svr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af19759a-00ba-443b-9d2c-44947f7042a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy Regressor (Random Split)\n",
      "R²   : -0.0009045969974690315\n",
      "RMSE: 7.840697074383431\n",
      "MAE : 6.152040816326531\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "\n",
    "y_dummy = all_features_data[\"Number of Admissions\"]\n",
    "\n",
    "X_dummy = all_features_data.drop(\n",
    "    columns=[\"Number of Admissions\", \"Timestamp\"]\n",
    ")\n",
    "\n",
    "X_train_dummy, X_test_dummy, y_train_dummy, y_test_dummy = train_test_split(\n",
    "    X_dummy, y_dummy, test_size=0.2, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "\n",
    "dummy_reg = DummyRegressor(strategy=\"mean\")\n",
    "dummy_reg.fit(X_train_dummy, y_train_dummy)\n",
    "\n",
    "y_pred_dummy = dummy_reg.predict(X_test_dummy)\n",
    "\n",
    "print(\"Dummy Regressor (Random Split)\")\n",
    "print(\"R²   :\", r2_score(y_test_dummy, y_pred_dummy))\n",
    "print(\"RMSE:\", np.sqrt(mean_squared_error(y_test_dummy, y_pred_dummy)))\n",
    "print(\"MAE :\", mean_absolute_error(y_test_dummy, y_pred_dummy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8beb3962-02b2-4f48-b19a-f2b1df06f6b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression (Random Split)\n",
      "--------------------------------\n",
      "R²   : 0.12584311318987063\n",
      "RMSE: 7.327452721434663\n",
      "MAE : 5.824296997025744\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "\n",
    "y_lin = all_features_data[\"Number of Admissions\"]\n",
    "\n",
    "X_lin = all_features_data.drop(\n",
    "    columns=[\n",
    "        \"Number of Admissions\",\n",
    "        \"Timestamp\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "X_train_lin, X_test_lin, y_train_lin, y_test_lin = train_test_split(\n",
    "    X_lin,\n",
    "    y_lin,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "\n",
    "lin_pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"linreg\", LinearRegression())\n",
    "])\n",
    "\n",
    "\n",
    "lin_pipeline.fit(X_train_lin, y_train_lin)\n",
    "\n",
    "\n",
    "y_pred_lin = lin_pipeline.predict(X_test_lin)\n",
    "\n",
    "print(\"Linear Regression (Random Split)\")\n",
    "print(\"--------------------------------\")\n",
    "print(\"R²   :\", r2_score(y_test_lin, y_pred_lin))\n",
    "print(\"RMSE:\", np.sqrt(mean_squared_error(y_test_lin, y_pred_lin)))\n",
    "print(\"MAE :\", mean_absolute_error(y_test_lin, y_pred_lin))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96f4b1c8-ecb3-4aa8-a08d-0f81a3427bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost (Random Split)\n",
      "R²   : 0.21273346014993866\n",
      "RMSE: 6.953752515306717\n",
      "MAE : 5.563463538033622\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "\n",
    "y_xgb_rand = all_features_data[\"Number of Admissions\"]\n",
    "\n",
    "X_xgb_rand = all_features_data.drop(\n",
    "    columns=[\"Number of Admissions\", \"Timestamp\"]\n",
    ")\n",
    "\n",
    "X_train_xgb_rand, X_test_xgb_rand, y_train_xgb_rand, y_test_xgb_rand = train_test_split(\n",
    "    X_xgb_rand, y_xgb_rand, test_size=0.2, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "\n",
    "xgb_rand = xgb.XGBRegressor(\n",
    "    n_estimators=300,\n",
    "    max_depth=4,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.85,\n",
    "    colsample_bytree=0.85,\n",
    "    objective=\"reg:squarederror\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb_rand.fit(X_train_xgb_rand, y_train_xgb_rand)\n",
    "y_pred_xgb_rand = xgb_rand.predict(X_test_xgb_rand)\n",
    "\n",
    "print(\"XGBoost (Random Split)\")\n",
    "print(\"R²   :\", r2_score(y_test_xgb_rand, y_pred_xgb_rand))\n",
    "print(\"RMSE:\", np.sqrt(mean_squared_error(y_test_xgb_rand, y_pred_xgb_rand)))\n",
    "print(\"MAE :\", mean_absolute_error(y_test_xgb_rand, y_pred_xgb_rand))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8670e4da-4d6f-42ea-8eb4-507a63a50292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost (Time-Aware Split)\n",
      "R²   : -0.19350324256615248\n",
      "RMSE: 8.099551815472129\n",
      "MAE : 6.584219269405137\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_xgb_time = all_features_data[\"Number of Admissions\"]\n",
    "\n",
    "X_xgb_time = all_features_data.drop(\n",
    "    columns=[\"Number of Admissions\", \"Timestamp\"]\n",
    ")\n",
    "\n",
    "split_date = \"2018-11-01\"\n",
    "\n",
    "train_idx = all_features_data[\"Timestamp\"] < split_date\n",
    "test_idx  = all_features_data[\"Timestamp\"] >= split_date\n",
    "\n",
    "X_train_xgb_time = X_xgb_time.loc[train_idx]\n",
    "X_test_xgb_time  = X_xgb_time.loc[test_idx]\n",
    "\n",
    "y_train_xgb_time = y_xgb_time.loc[train_idx]\n",
    "y_test_xgb_time  = y_xgb_time.loc[test_idx]\n",
    "\n",
    "\n",
    "xgb_time = xgb.XGBRegressor(\n",
    "    n_estimators=300,\n",
    "    max_depth=4,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.85,\n",
    "    colsample_bytree=0.85,\n",
    "    objective=\"reg:squarederror\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb_time.fit(X_train_xgb_time, y_train_xgb_time)\n",
    "y_pred_xgb_time = xgb_time.predict(X_test_xgb_time)\n",
    "\n",
    "print(\"XGBoost (Time-Aware Split)\")\n",
    "print(\"R²   :\", r2_score(y_test_xgb_time, y_pred_xgb_time))\n",
    "print(\"RMSE:\", np.sqrt(mean_squared_error(y_test_xgb_time, y_pred_xgb_time)))\n",
    "print(\"MAE :\", mean_absolute_error(y_test_xgb_time, y_pred_xgb_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11bda37b-70f5-4de0-a4ab-08f902dbda5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest (Random Split)\n",
      "R²   : 0.227951248165697\n",
      "RMSE: 6.886216867937668\n",
      "MAE : 5.464008620326992\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "y_rf_rand = all_features_data[\"Number of Admissions\"]\n",
    "\n",
    "X_rf_rand = all_features_data.drop(\n",
    "    columns=[\"Number of Admissions\", \"Timestamp\"]\n",
    ")\n",
    "\n",
    "X_train_rf_rand, X_test_rf_rand, y_train_rf_rand, y_test_rf_rand = train_test_split(\n",
    "    X_rf_rand, y_rf_rand, test_size=0.2, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "\n",
    "rf_rand = RandomForestRegressor(\n",
    "    n_estimators=300,\n",
    "    max_depth=None,\n",
    "    min_samples_leaf=5,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_rand.fit(X_train_rf_rand, y_train_rf_rand)\n",
    "y_pred_rf_rand = rf_rand.predict(X_test_rf_rand)\n",
    "\n",
    "print(\"Random Forest (Random Split)\")\n",
    "print(\"R²   :\", r2_score(y_test_rf_rand, y_pred_rf_rand))\n",
    "print(\"RMSE:\", np.sqrt(mean_squared_error(y_test_rf_rand, y_pred_rf_rand)))\n",
    "print(\"MAE :\", mean_absolute_error(y_test_rf_rand, y_pred_rf_rand))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64a6ba2d-f03e-4f93-9dcd-a7ce423615fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest (Time-Aware Split)\n",
      "R²   : -0.18877831574571102\n",
      "RMSE: 8.083503370984662\n",
      "MAE : 6.5292611488385575\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_rf_time = all_features_data[\"Number of Admissions\"]\n",
    "\n",
    "X_rf_time = all_features_data.drop(\n",
    "    columns=[\"Number of Admissions\", \"Timestamp\"]\n",
    ")\n",
    "\n",
    "X_train_rf_time = X_rf_time.loc[train_idx]\n",
    "X_test_rf_time  = X_rf_time.loc[test_idx]\n",
    "\n",
    "y_train_rf_time = y_rf_time.loc[train_idx]\n",
    "y_test_rf_time  = y_rf_time.loc[test_idx]\n",
    "\n",
    "\n",
    "rf_time = RandomForestRegressor(\n",
    "    n_estimators=300,\n",
    "    max_depth=None,\n",
    "    min_samples_leaf=5,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_time.fit(X_train_rf_time, y_train_rf_time)\n",
    "y_pred_rf_time = rf_time.predict(X_test_rf_time)\n",
    "\n",
    "print(\"Random Forest (Time-Aware Split)\")\n",
    "print(\"R²   :\", r2_score(y_test_rf_time, y_pred_rf_time))\n",
    "print(\"RMSE:\", np.sqrt(mean_squared_error(y_test_rf_time, y_pred_rf_time)))\n",
    "print(\"MAE :\", mean_absolute_error(y_test_rf_time, y_pred_rf_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0856dc81-efbc-4fbb-908c-071c44c2d29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost (Random Split)\n",
      "R²   : 0.16470116762671538\n",
      "RMSE: 7.16274137553682\n",
      "MAE : 5.62397997038705\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "\n",
    "y_xgb_rand_c = all_features_data[\"Number of Admissions\"]\n",
    "\n",
    "X_xgb_rand_c = all_features_data.drop(\n",
    "    columns=[\n",
    "    \"Number of Admissions\",\n",
    "    \"Timestamp\",\n",
    "    \"Index Value\",\n",
    "    \"NO (µg/m³)\",\n",
    "    \"NOx (ppb)\",\n",
    "    \"NH3 (µg/m³)\",\n",
    "    \"Benzene (µg/m³)\",\n",
    "    \"Toluene (µg/m³)\",\n",
    "    \"temperature_2m_min (°C)\",\n",
    "    \"apparent_temperature_mean (°C)\",\n",
    "    \"apparent_temperature_max (°C)\",\n",
    "    \"apparent_temperature_min (°C)\",\n",
    "    \"wind_gusts_10m_max (km/h)\"\n",
    "]\n",
    ")\n",
    "\n",
    "X_train_xgb_rand_c, X_test_xgb_rand_c, y_train_xgb_rand_c, y_test_xgb_rand_c = train_test_split(\n",
    "    X_xgb_rand_c, y_xgb_rand_c, test_size=0.2, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "\n",
    "xgb_rand_c = xgb.XGBRegressor(\n",
    "    n_estimators=300,\n",
    "    max_depth=4,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.85,\n",
    "    colsample_bytree=0.85,\n",
    "    objective=\"reg:squarederror\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb_rand_c.fit(X_train_xgb_rand_c, y_train_xgb_rand_c)\n",
    "y_pred_xgb_rand_c = xgb_rand_c.predict(X_test_xgb_rand_c)\n",
    "\n",
    "print(\"XGBoost (Random Split)\")\n",
    "print(\"R²   :\", r2_score(y_test_xgb_rand_c, y_pred_xgb_rand_c))\n",
    "print(\"RMSE:\", np.sqrt(mean_squared_error(y_test_xgb_rand_c, y_pred_xgb_rand_c)))\n",
    "print(\"MAE :\", mean_absolute_error(y_test_xgb_rand_c, y_pred_xgb_rand_c))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b8315461-71bd-42f7-9756-0dd8cbf3254e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Timestamp', 'PM2.5 (µg/m³)', 'PM10 (µg/m³)', 'NO (µg/m³)', 'NO2 (µg/m³)', 'NOx (ppb)', 'NH3 (µg/m³)', 'SO2 (µg/m³)', 'CO (mg/m³)', 'Ozone (µg/m³)', 'Benzene (µg/m³)', 'Toluene (µg/m³)', 'Index Value', 'temperature_2m_mean (°C)', 'temperature_2m_max (°C)', 'temperature_2m_min (°C)', 'apparent_temperature_mean (°C)', 'apparent_temperature_max (°C)', 'apparent_temperature_min (°C)', 'wind_speed_10m_max (km/h)', 'wind_gusts_10m_max (km/h)', 'wind_direction_10m_dominant (°)', 'Number of Admissions']\n"
     ]
    }
   ],
   "source": [
    "print(all_features_data.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d10f08f9-ad52-4504-923c-5b65cd1717cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest (Random Split)\n",
      "R² : 0.16925717905630489\n",
      "RMSE: 7.143180620303536\n",
      "MAE : 5.665833728524794\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# =========================\n",
    "# Target\n",
    "# =========================\n",
    "y_rf_rand_c = all_features_data[\"Number of Admissions\"]\n",
    "\n",
    "# =========================\n",
    "# Features (same dropped columns as XGBoost)\n",
    "# =========================\n",
    "X_rf_rand_c = all_features_data.drop(\n",
    "    columns=[\n",
    "        \"Number of Admissions\",\n",
    "        \"Timestamp\",\n",
    "        \"Index Value\",\n",
    "        \"NO (µg/m³)\",\n",
    "        \"NOx (ppb)\",\n",
    "        \"NH3 (µg/m³)\",\n",
    "        \"Benzene (µg/m³)\",\n",
    "        \"Toluene (µg/m³)\",\n",
    "        \"temperature_2m_min (°C)\",\n",
    "        \"apparent_temperature_mean (°C)\",\n",
    "        \"apparent_temperature_max (°C)\",\n",
    "        \"apparent_temperature_min (°C)\",\n",
    "        \"wind_gusts_10m_max (km/h)\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# Wind direction encoding (same idea, new vars)\n",
    "# =========================\n",
    "X_rf_rand_c[\"wind_dir_sin\"] = np.sin(\n",
    "    np.deg2rad(X_rf_rand_c[\"wind_direction_10m_dominant (°)\"])\n",
    ")\n",
    "X_rf_rand_c[\"wind_dir_cos\"] = np.cos(\n",
    "    np.deg2rad(X_rf_rand_c[\"wind_direction_10m_dominant (°)\"])\n",
    ")\n",
    "\n",
    "X_rf_rand_c = X_rf_rand_c.drop(\n",
    "    columns=[\"wind_direction_10m_dominant (°)\"]\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# Train-test split (random, same as XGB)\n",
    "# =========================\n",
    "X_train_rf_rand_c, X_test_rf_rand_c, y_train_rf_rand_c, y_test_rf_rand_c = train_test_split(\n",
    "    X_rf_rand_c,\n",
    "    y_rf_rand_c,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# Random Forest model\n",
    "# =========================\n",
    "rf_rand_c = RandomForestRegressor(\n",
    "    n_estimators=300,\n",
    "    max_depth=4,              # matches XGB tree depth\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    max_features=0.85,        # analogous to colsample_bytree\n",
    "    bootstrap=True,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# Train & predict\n",
    "# =========================\n",
    "rf_rand_c.fit(X_train_rf_rand_c, y_train_rf_rand_c)\n",
    "y_pred_rf_rand_c = rf_rand_c.predict(X_test_rf_rand_c)\n",
    "\n",
    "# =========================\n",
    "# Evaluation (same metrics)\n",
    "# =========================\n",
    "print(\"Random Forest (Random Split)\")\n",
    "print(\"R² :\", r2_score(y_test_rf_rand_c, y_pred_rf_rand_c))\n",
    "print(\"RMSE:\", np.sqrt(mean_squared_error(y_test_rf_rand_c, y_pred_rf_rand_c)))\n",
    "print(\"MAE :\", mean_absolute_error(y_test_rf_rand_c, y_pred_rf_rand_c))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "94a01bb2-4461-4ab9-9a6e-63895bcba8b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest (Random Split, No Wind Direction)\n",
      "R² : 0.1724285358265929\n",
      "RMSE: 7.129533053936597\n",
      "MAE : 5.684488434260923\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# =========================\n",
    "# Target\n",
    "# =========================\n",
    "y_rf_rand_c = all_features_data[\"Number of Admissions\"]\n",
    "\n",
    "# =========================\n",
    "# Features (drop redundant + wind direction)\n",
    "# =========================\n",
    "X_rf_rand_c = all_features_data.drop(\n",
    "    columns=[\n",
    "        \"Number of Admissions\",\n",
    "        \"Timestamp\",\n",
    "        \"Index Value\",\n",
    "        \"NO (µg/m³)\",\n",
    "        \"NOx (ppb)\",\n",
    "        \"NH3 (µg/m³)\",\n",
    "        \"Benzene (µg/m³)\",\n",
    "        \"Toluene (µg/m³)\",\n",
    "        \"temperature_2m_min (°C)\",\n",
    "        \"apparent_temperature_mean (°C)\",\n",
    "        \"apparent_temperature_max (°C)\",\n",
    "        \"apparent_temperature_min (°C)\",\n",
    "        \"wind_gusts_10m_max (km/h)\",\n",
    "        \"wind_direction_10m_dominant (°)\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# Train-test split (random)\n",
    "# =========================\n",
    "X_train_rf_rand_c, X_test_rf_rand_c, y_train_rf_rand_c, y_test_rf_rand_c = train_test_split(\n",
    "    X_rf_rand_c,\n",
    "    y_rf_rand_c,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# Random Forest model\n",
    "# =========================\n",
    "rf_rand_c = RandomForestRegressor(\n",
    "    n_estimators=300,\n",
    "    max_depth=4,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    max_features=0.85,\n",
    "    bootstrap=True,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# Train & predict\n",
    "# =========================\n",
    "rf_rand_c.fit(X_train_rf_rand_c, y_train_rf_rand_c)\n",
    "y_pred_rf_rand_c = rf_rand_c.predict(X_test_rf_rand_c)\n",
    "\n",
    "# =========================\n",
    "# Evaluation\n",
    "# =========================\n",
    "print(\"Random Forest (Random Split, No Wind Direction)\")\n",
    "print(\"R² :\", r2_score(y_test_rf_rand_c, y_pred_rf_rand_c))\n",
    "print(\"RMSE:\", np.sqrt(mean_squared_error(y_test_rf_rand_c, y_pred_rf_rand_c)))\n",
    "print(\"MAE :\", mean_absolute_error(y_test_rf_rand_c, y_pred_rf_rand_c))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4cd175c1-1d03-4b75-8b6b-0020a6b6a442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost (Random Split, With Wind Direction)\n",
      "R² : 0.15215327022090808\n",
      "RMSE: 7.216340349184611\n",
      "MAE : 5.72918575831822\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "# =========================\n",
    "# Target\n",
    "# =========================\n",
    "y_xgb_rand_c = all_features_data[\"Number of Admissions\"]\n",
    "\n",
    "# =========================\n",
    "# Features (drop redundant)\n",
    "# =========================\n",
    "X_xgb_rand_c = all_features_data.drop(\n",
    "    columns=[\n",
    "        \"Number of Admissions\",\n",
    "        \"Timestamp\",\n",
    "        \"Index Value\",\n",
    "        \"NO (µg/m³)\",\n",
    "        \"NOx (ppb)\",\n",
    "        \"NH3 (µg/m³)\",\n",
    "        \"Benzene (µg/m³)\",\n",
    "        \"Toluene (µg/m³)\",\n",
    "        \"temperature_2m_min (°C)\",\n",
    "        \"apparent_temperature_mean (°C)\",\n",
    "        \"apparent_temperature_max (°C)\",\n",
    "        \"apparent_temperature_min (°C)\",\n",
    "        \"wind_gusts_10m_max (km/h)\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# Wind direction encoding\n",
    "# =========================\n",
    "X_xgb_rand_c[\"wind_dir_sin\"] = np.sin(\n",
    "    np.deg2rad(X_xgb_rand_c[\"wind_direction_10m_dominant (°)\"])\n",
    ")\n",
    "X_xgb_rand_c[\"wind_dir_cos\"] = np.cos(\n",
    "    np.deg2rad(X_xgb_rand_c[\"wind_direction_10m_dominant (°)\"])\n",
    ")\n",
    "\n",
    "X_xgb_rand_c = X_xgb_rand_c.drop(\n",
    "    columns=[\"wind_direction_10m_dominant (°)\"]\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# Train-test split (random)\n",
    "# =========================\n",
    "X_train_xgb_rand_c, X_test_xgb_rand_c, y_train_xgb_rand_c, y_test_xgb_rand_c = train_test_split(\n",
    "    X_xgb_rand_c,\n",
    "    y_xgb_rand_c,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# XGBoost model (same as yours)\n",
    "# =========================\n",
    "xgb_rand_c = xgb.XGBRegressor(\n",
    "    n_estimators=300,\n",
    "    max_depth=4,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.85,\n",
    "    colsample_bytree=0.85,\n",
    "    objective=\"reg:squarederror\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# Train & predict\n",
    "# =========================\n",
    "xgb_rand_c.fit(X_train_xgb_rand_c, y_train_xgb_rand_c)\n",
    "y_pred_xgb_rand_c = xgb_rand_c.predict(X_test_xgb_rand_c)\n",
    "\n",
    "# =========================\n",
    "# Evaluation\n",
    "# =========================\n",
    "print(\"XGBoost (Random Split, With Wind Direction)\")\n",
    "print(\"R² :\", r2_score(y_test_xgb_rand_c, y_pred_xgb_rand_c))\n",
    "print(\"RMSE:\", np.sqrt(mean_squared_error(y_test_xgb_rand_c, y_pred_xgb_rand_c)))\n",
    "print(\"MAE :\", mean_absolute_error(y_test_xgb_rand_c, y_pred_xgb_rand_c))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0381b5fe-10cd-40a9-90f4-ea2282f825b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n",
      "Fold 1 | R²=0.210, RMSE=6.966, MAE=5.510\n",
      "Fold 2 | R²=0.093, RMSE=7.282, MAE=5.802\n",
      "Fold 3 | R²=0.069, RMSE=7.455, MAE=5.673\n",
      "Fold 4 | R²=0.100, RMSE=6.849, MAE=5.513\n",
      "Fold 5 | R²=0.085, RMSE=6.882, MAE=5.422\n",
      "\n",
      "XGBoost – 5 Fold CV (Random, No Wind Direction)\n",
      "Mean R²  : 0.112\n",
      "Mean RMSE: 7.087\n",
      "Mean MAE : 5.584\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "# =========================\n",
    "# Target\n",
    "# =========================\n",
    "y_xgb_cv5_rand_c = all_features_data[\"Number of Admissions\"]\n",
    "\n",
    "# =========================\n",
    "# Features (drop redundant + wind direction)\n",
    "# =========================\n",
    "X_xgb_cv5_rand_c = all_features_data.drop(\n",
    "    columns=[\n",
    "        \"Number of Admissions\",\n",
    "        \"Timestamp\",\n",
    "        \"Index Value\",\n",
    "        \"NO (µg/m³)\",\n",
    "        \"NOx (ppb)\",\n",
    "        \"NH3 (µg/m³)\",\n",
    "        \"Benzene (µg/m³)\",\n",
    "        \"Toluene (µg/m³)\",\n",
    "        \"temperature_2m_min (°C)\",\n",
    "        \"apparent_temperature_mean (°C)\",\n",
    "        \"apparent_temperature_max (°C)\",\n",
    "        \"apparent_temperature_min (°C)\",\n",
    "        \"wind_gusts_10m_max (km/h)\",\n",
    "        \"wind_direction_10m_dominant (°)\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# 5-Fold Cross-Validation setup\n",
    "# =========================\n",
    "kf_xgb_cv5_rand_c = KFold(\n",
    "    n_splits=5,\n",
    "    shuffle=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# Storage for metrics\n",
    "# =========================\n",
    "r2_scores_xgb_cv5_rand_c = []\n",
    "rmse_scores_xgb_cv5_rand_c = []\n",
    "mae_scores_xgb_cv5_rand_c = []\n",
    "\n",
    "# =========================\n",
    "# CV loop\n",
    "# =========================\n",
    "for fold_idx_xgb_cv5_rand_c, (train_idx_xgb_cv5_rand_c, test_idx_xgb_cv5_rand_c) in enumerate(\n",
    "    kf_xgb_cv5_rand_c.split(X_xgb_cv5_rand_c), start=1\n",
    "):\n",
    "    X_train_xgb_cv5_rand_c = X_xgb_cv5_rand_c.iloc[train_idx_xgb_cv5_rand_c]\n",
    "    X_test_xgb_cv5_rand_c  = X_xgb_cv5_rand_c.iloc[test_idx_xgb_cv5_rand_c]\n",
    "\n",
    "    y_train_xgb_cv5_rand_c = y_xgb_cv5_rand_c.iloc[train_idx_xgb_cv5_rand_c]\n",
    "    y_test_xgb_cv5_rand_c  = y_xgb_cv5_rand_c.iloc[test_idx_xgb_cv5_rand_c]\n",
    "\n",
    "    model_xgb_cv5_rand_c = xgb.XGBRegressor(\n",
    "        n_estimators=300,\n",
    "        max_depth=4,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.85,\n",
    "        colsample_bytree=0.85,\n",
    "        objective=\"reg:squarederror\",\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    model_xgb_cv5_rand_c.fit(X_train_xgb_cv5_rand_c, y_train_xgb_cv5_rand_c)\n",
    "\n",
    "    y_pred_xgb_cv5_rand_c = model_xgb_cv5_rand_c.predict(\n",
    "        X_test_xgb_cv5_rand_c\n",
    "    )\n",
    "\n",
    "    # Metrics\n",
    "    r2_scores_xgb_cv5_rand_c.append(\n",
    "        r2_score(y_test_xgb_cv5_rand_c, y_pred_xgb_cv5_rand_c)\n",
    "    )\n",
    "    rmse_scores_xgb_cv5_rand_c.append(\n",
    "        np.sqrt(mean_squared_error(y_test_xgb_cv5_rand_c, y_pred_xgb_cv5_rand_c))\n",
    "    )\n",
    "    mae_scores_xgb_cv5_rand_c.append(\n",
    "        mean_absolute_error(y_test_xgb_cv5_rand_c, y_pred_xgb_cv5_rand_c)\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"Fold {fold_idx_xgb_cv5_rand_c} | \"\n",
    "        f\"R²={r2_scores_xgb_cv5_rand_c[-1]:.3f}, \"\n",
    "        f\"RMSE={rmse_scores_xgb_cv5_rand_c[-1]:.3f}, \"\n",
    "        f\"MAE={mae_scores_xgb_cv5_rand_c[-1]:.3f}\"\n",
    "    )\n",
    "\n",
    "# =========================\n",
    "# Mean CV performance\n",
    "# =========================\n",
    "print(\"\\nXGBoost – 5 Fold CV (Random, No Wind Direction)\")\n",
    "print(f\"Mean R²  : {np.mean(r2_scores_xgb_cv5_rand_c):.3f}\")\n",
    "print(f\"Mean RMSE: {np.mean(rmse_scores_xgb_cv5_rand_c):.3f}\")\n",
    "print(f\"Mean MAE : {np.mean(mae_scores_xgb_cv5_rand_c):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3666bae5-2458-464f-8152-98cff487fd9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 | R²=0.237, RMSE=6.847, MAE=5.434\n",
      "Fold 2 | R²=0.120, RMSE=7.175, MAE=5.724\n",
      "Fold 3 | R²=0.070, RMSE=7.455, MAE=5.760\n",
      "Fold 4 | R²=0.122, RMSE=6.767, MAE=5.353\n",
      "Fold 5 | R²=0.089, RMSE=6.864, MAE=5.650\n",
      "\n",
      "XGBoost – 5 Fold CV (Random, ALL Features)\n",
      "Mean R²  : 0.127\n",
      "Mean RMSE: 7.021\n",
      "Mean MAE : 5.584\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "# =========================\n",
    "# Target\n",
    "# =========================\n",
    "y_xgb_cv5_all_c = all_features_data[\"Number of Admissions\"]\n",
    "\n",
    "# =========================\n",
    "# Features (ALL columns except target)\n",
    "# =========================\n",
    "X_xgb_cv5_all_c = all_features_data.drop(\n",
    "    columns=[\"Number of Admissions\", \"Timestamp\"]\n",
    ")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 5-Fold Cross-Validation setup\n",
    "# =========================\n",
    "kf_xgb_cv5_all_c = KFold(\n",
    "    n_splits=5,\n",
    "    shuffle=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# Storage for metrics\n",
    "# =========================\n",
    "r2_scores_xgb_cv5_all_c = []\n",
    "rmse_scores_xgb_cv5_all_c = []\n",
    "mae_scores_xgb_cv5_all_c = []\n",
    "\n",
    "# =========================\n",
    "# CV loop\n",
    "# =========================\n",
    "for fold_idx_xgb_cv5_all_c, (\n",
    "    train_idx_xgb_cv5_all_c,\n",
    "    test_idx_xgb_cv5_all_c\n",
    ") in enumerate(kf_xgb_cv5_all_c.split(X_xgb_cv5_all_c), start=1):\n",
    "\n",
    "    X_train_xgb_cv5_all_c = X_xgb_cv5_all_c.iloc[train_idx_xgb_cv5_all_c]\n",
    "    X_test_xgb_cv5_all_c  = X_xgb_cv5_all_c.iloc[test_idx_xgb_cv5_all_c]\n",
    "\n",
    "    y_train_xgb_cv5_all_c = y_xgb_cv5_all_c.iloc[train_idx_xgb_cv5_all_c]\n",
    "    y_test_xgb_cv5_all_c  = y_xgb_cv5_all_c.iloc[test_idx_xgb_cv5_all_c]\n",
    "\n",
    "    model_xgb_cv5_all_c = xgb.XGBRegressor(\n",
    "        n_estimators=300,\n",
    "        max_depth=4,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.85,\n",
    "        colsample_bytree=0.85,\n",
    "        objective=\"reg:squarederror\",\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    model_xgb_cv5_all_c.fit(\n",
    "        X_train_xgb_cv5_all_c,\n",
    "        y_train_xgb_cv5_all_c\n",
    "    )\n",
    "\n",
    "    y_pred_xgb_cv5_all_c = model_xgb_cv5_all_c.predict(\n",
    "        X_test_xgb_cv5_all_c\n",
    "    )\n",
    "\n",
    "    # Metrics\n",
    "    r2_scores_xgb_cv5_all_c.append(\n",
    "        r2_score(y_test_xgb_cv5_all_c, y_pred_xgb_cv5_all_c)\n",
    "    )\n",
    "    rmse_scores_xgb_cv5_all_c.append(\n",
    "        np.sqrt(mean_squared_error(y_test_xgb_cv5_all_c, y_pred_xgb_cv5_all_c))\n",
    "    )\n",
    "    mae_scores_xgb_cv5_all_c.append(\n",
    "        mean_absolute_error(y_test_xgb_cv5_all_c, y_pred_xgb_cv5_all_c)\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"Fold {fold_idx_xgb_cv5_all_c} | \"\n",
    "        f\"R²={r2_scores_xgb_cv5_all_c[-1]:.3f}, \"\n",
    "        f\"RMSE={rmse_scores_xgb_cv5_all_c[-1]:.3f}, \"\n",
    "        f\"MAE={mae_scores_xgb_cv5_all_c[-1]:.3f}\"\n",
    "    )\n",
    "\n",
    "# =========================\n",
    "# Mean CV performance\n",
    "# =========================\n",
    "print(\"\\nXGBoost – 5 Fold CV (Random, ALL Features)\")\n",
    "print(f\"Mean R²  : {np.mean(r2_scores_xgb_cv5_all_c):.3f}\")\n",
    "print(f\"Mean RMSE: {np.mean(rmse_scores_xgb_cv5_all_c):.3f}\")\n",
    "print(f\"Mean MAE : {np.mean(mae_scores_xgb_cv5_all_c):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cf49d0-188c-4437-b998-a2b8bb250d96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (research2)",
   "language": "python",
   "name": "research2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
